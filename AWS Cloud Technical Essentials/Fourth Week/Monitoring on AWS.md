When you have a solution built out of many different pieces, like how we build solutions on AWS, it's important to be able to see how different services are operating over time and react to operational events as they're happening. Let's consider the Employee Directory application. It's Monday morning and the users are seeing latency on page loads. It's probably not good enough to wait until a user sees the slowdown, calls, or enters a ticket saying, "Hello, your application is running slow." If you receive a call or a ticket from your users, you can then react and troubleshoot the issue. Waiting for users to notice and report issues to investigate will generally lead to unhappy end users. Ideally, you'd be able to respond to operational issues before your end users notice. On top of that, the end user can only provide information about their experience, and they cannot give insight into the inner workings of your solution. So, they can report the issue to you. But where's that issue coming from? Is it an EC2 problem? Is it a database problem? Is it a code change that has recently been deployed? Without monitoring, you have to do some digging to figure all of that out. So what do we need to do? The first step is to put proper monitoring in place. Monitoring is a verb. It's something we do. We collect metrics, we collect logs, we watch network traffic. The data needed to help you pinpoint problems comes from the different services and infrastructure hosting the application, and monitoring tools help you collect the data being generated by these systems. In a cloud environment that is ever-changing and ever-scaling, it's even more important to collect various types of information about the systems as they scale up and down and change over time. 
# __
![[Pasted image 20230707202444.png]]
The different services that make up your solution generate data points that we call metrics. Metrics that are monitored over time are called statistics. And metric is a data point like the current CPU utilization of an EC2 instance, where other data you monitor could come from different forms like log files. For example, your network will generate data like flow logs so you can see how network traffic is coming into and out of your VPC. 
# __
![[Pasted image 20230707202552.png]]
The servers will be generating metrics such as how much CPU is currently being used, or how much network traffic the instance is accepting at any given moment. Then finally, one more example is your database layer, which will generate metrics such as the number of simultaneous connections to your database. 
# __
So you need a way to collect all of this information. Once it's collected, it can be used to establish a baseline, and this baseline can be used to determine if things are operating smoothly or not. If the information collected deviates too far from the baseline, you would then trigger automatic alerts to go out to someone or something to try to remediate the issue. A good monitoring solution gathers data in one centralized location so you can proactively monitor and operate your system to keep your end users happy as well as allows for automated tasks to be triggered based on the data coming in. 
# __
![[Pasted image 20230707202651.png]]
This is where Amazon CloudWatch comes in. CloudWatch allows you to monitor your solutions all in one place. Data will be collected from your cloud-based infrastructure so you can see things like database metrics coming from RDS or DynamoDB, alongside EC2 metrics, as well as metrics coming from other services making up your AWS solution. Coming up next, we'll dive into some CloudWatch features and use cases.