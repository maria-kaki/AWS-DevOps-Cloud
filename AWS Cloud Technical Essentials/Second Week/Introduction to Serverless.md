When using Amazon EC2 or container services running on top of EC2 as a compute platform, you are required to set up and manage your fleet of instances. This means that you are responsible for patching your instances when new software packages or security updates come out, setting up the scaling of those instances, as well as ensuring that you've architected your solutions to be hosted in a highly available manner which means deploying instances across two AZs at a minimum as we discussed earlier. This is less management and operational overhead than you would have if you hosted the same solutions on premises but management processes will still need to be in place, and it's your responsibility to create those processes to fit your use case. This is actually really great and in many use cases is exactly what you want because it gives you a great deal of control over your solutions. Whatever happens on your instances and with your instances is in your hands. You can create simple or complicated setups that run in scale on AWS exactly to your specification. That being said, not every single solution requires this level of control over the underlying environment. Oftentimes, you might be looking to focus on your own business solutions and let someone else take care of the undifferentiated heavy lifting for you. Or perhaps you just simply don't want to fiddle around with scaling controls and fault tolerant designs but you still want all of the benefits of doing so. This is where the term serverless comes in. A lot of AWS services are serverless in nature. Serverless means that you cannot see or access the underlying infrastructure or instances that are hosting your solution. Instead, all of the management of the underlying environment from a provisioning, scaling, fault tolerance, and maintenance perspective are taken care of for you. All you need to do is focus on your application. The rest is taken care of, or more accurately the rest is abstracted from you. This means that serverless offerings are very convenient to use. You get to focus on the value that the service delivers and not the underlying implementation details thus reducing the number of operational support processes that you need to have in place. Remember the shared responsibility model that we covered in a previous lesson? This idea of serverless impacts that as well. For example, with Amazon EC2 instances, you are required to patch the OS when new security updates are released. With serverless offerings, the line between what you are responsible for versus what AWS is responsible for moves up. You do not have access to the underlying operating system that is running the service. Therefore, you cannot be responsible for carrying out tasks like patching. You are, however, still responsible for things like data encryption and access management. Let's wrap this up. I like to think of AWS services as existing on a spectrum. 
# __
![[Pasted image 20230703110837.png]]
On one side of the spectrum, you have convenience and on the other side, you have control. Many services exist to give you control like Amazon EC2 whereas other services exist to give you convenience, like the serverless compute AWS Lambda. We'll dive deeper into some of these serverless compute technologies coming up.
# __